class EfficientNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(EfficientNetV2Model, self).__init__()
        # Load pre-trained EfficientNetV2
        self.base_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)
        # Replace the classifier with a custom one
        self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)

    def forward(self, x):
        return self.base_model(x)

num_classes = len(train_dataset.classes)
model = EfficientNetV2Model(num_classes).to(device)

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)

# Learning rate scheduler
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)

# Training function
def train(model, loader, optimizer, criterion):
    model.train()
    running_loss, correct = 0.0, 0
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        correct += (outputs.argmax(1) == labels).sum().item()
    return running_loss / len(loader), correct / len(loader.dataset)


# Testing function
def test(model, loader):
    model.eval()
    correct = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            correct += (outputs.argmax(1) == labels).sum().item()
    return correct / len(loader.dataset)

# Training loop
num_epochs = 6
patience = 3
best_accuracy = 0.0
best_epoch = 0

train_losses = []
test_losses = []
train_accuracies = []
test_accuracies = []

for epoch in range(num_epochs):
    train_loss, train_acc = train(model, train_loader, optimizer, criterion)
    test_acc = test(model, val_loader)
    scheduler.step()

    train_losses.append(train_loss)
    train_accuracies.append(train_acc) # Append train_acc
    test_accuracies.append(test_acc)

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"  ➤ Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}")
    print(f"  ➤ test   Accuracy: {test_acc:.4f}")


    if test_acc > best_accuracy:
        best_accuracy = test_acc
        best_epoch = epoch
        print(f"  ✅ Best model saved at epoch {epoch+1} with accuracy: {best_accuracy:.4f}")
    elif epoch - best_epoch >= patience:
        print(f"  ⛔ Early stopping at epoch {epoch+1}. No improvement for {patience} epochs.")
        break