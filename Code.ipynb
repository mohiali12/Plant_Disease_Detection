{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5kEyri4IthA"
      },
      "outputs": [],
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computationss\n",
        "import pandas as pd             # for working with dataframes\n",
        "import torch                    # Pytorch module\n",
        "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
        "import torch.nn as nn           # for creating  neural networks\n",
        "from torch.utils.data import DataLoader # for dataloaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXVM94N1At8s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGQDhr4jJF7s"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/cotton data\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "test_dir = data_dir + \"/test\"\n",
        "diseases = os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QficyxpaJIB-"
      },
      "outputs": [],
      "source": [
        "print(diseases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rFgfotRJL5W"
      },
      "outputs": [],
      "source": [
        "print(\"Total disease classes are: {}\".format(len(diseases)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeWW7-CYCjeN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_dataset(dataset_path):\n",
        "    \"\"\"\n",
        "    Count the number of images in a dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the root directory of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of images in the dataset.\n",
        "    \"\"\"\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']  # Add supported image formats\n",
        "    total_images = 0\n",
        "\n",
        "    # Walk through the dataset directory\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            # Check if the file has a valid image extension\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                total_images += 1\n",
        "\n",
        "    return total_images\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = \"/content/drive/MyDrive/cotton data\"  # Replace with your dataset path\n",
        "    total_images = count_images_in_dataset(dataset_path)\n",
        "    print(f\"Total number of images in the dataset: {total_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNtcFwhfJQK2"
      },
      "outputs": [],
      "source": [
        "plants = []\n",
        "NumberOfDiseases = 0\n",
        "for plant in diseases:\n",
        "    parts = plant.split('___')\n",
        "    if len(parts) > 0 and parts[0] not in plants:  # Check if there's at least one element\n",
        "        plants.append(parts[0])\n",
        "    if len(parts) > 1 and parts[1] != 'healthy':  # Check if there's a second element\n",
        "        NumberOfDiseases += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fECOWZL2JWHF"
      },
      "outputs": [],
      "source": [
        "print(\"Number of plants: {}\".format(len(plants)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2QT6WaNJdjD"
      },
      "outputs": [],
      "source": [
        "nums = {}\n",
        "for disease in diseases:\n",
        "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
        "\n",
        "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
        "\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKXvzWOaJgUz"
      },
      "outputs": [],
      "source": [
        "index = list(range(len(diseases)))\n",
        "plt.figure(figsize=(20, 5))\n",
        "# Use diseases as the x-axis labels and corresponding values from nums as heights\n",
        "plt.bar(index, list(nums.values()), width=0.3)\n",
        "plt.xlabel('Plants/Diseases', fontsize=10)\n",
        "plt.ylabel('No of images available', fontsize=10)\n",
        "# Rotating x-axis labels for better readability\n",
        "plt.xticks(index, diseases, fontsize=15, rotation=90)\n",
        "plt.title('Images per each class of plant disease')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uneWhXxJuEG"
      },
      "outputs": [],
      "source": [
        "n_train = 0\n",
        "for value in nums.values():\n",
        "    n_train += value\n",
        "print(f\"There are {n_train} images for training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJSAUbzpJ0B3"
      },
      "outputs": [],
      "source": [
        "# datasets for validation and training\n",
        "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKX6hzMsJ3QM"
      },
      "outputs": [],
      "source": [
        "img, label = train[0]\n",
        "print(img.shape, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5atlYWVJ5Mx"
      },
      "outputs": [],
      "source": [
        "len(train.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NY-X5x-J9L-"
      },
      "outputs": [],
      "source": [
        "def show_image(image, label):\n",
        "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
        "    plt.imshow(image.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU4n_7ZGJ-g7"
      },
      "outputs": [],
      "source": [
        "show_image(*train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbEUobdtKDgg"
      },
      "outputs": [],
      "source": [
        "show_image(*train[300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOqzLYVxKPx7"
      },
      "outputs": [],
      "source": [
        "random_seed = 7\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdfezDjgKRju"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq6TerdEKVlM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader # Import DataLoader from torch.utils.data\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_dl = DataLoader(test, batch_size, num_workers=0, pin_memory=True)\n",
        "\n",
        "# ... (The rest of your code) ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9aJJ6JuKWkw"
      },
      "outputs": [],
      "source": [
        "# helper function to show a batch of training instances\n",
        "def show_batch(data):\n",
        "    for images, labels in data:\n",
        "        fig, ax = plt.subplots(figsize=(30, 30))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr6xIHzKKZ4J"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to a common size\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaTEBosSKdSl"
      },
      "outputs": [],
      "source": [
        "train = ImageFolder(train_dir, transform=transform)\n",
        "test = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_dl = DataLoader(test, batch_size, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm4kZ06cKgOd"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Define a transform to resize and convert images to tensors\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to a common size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# datasets for validation and training with the resize transform\n",
        "train = ImageFolder(train_dir, transform=transform)\n",
        "test = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# ... (The rest of your code) ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRC8DXAtKjUT"
      },
      "outputs": [],
      "source": [
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wMLd-4YVlRO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Slightly more stable crop range\n",
        "        transforms.RandomApply([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.RandomRotation(degrees=30)\n",
        "        ], p=0.7),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.05)\n",
        "        ], p=0.5),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),  # optional: helps generalize\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),  # More robust than Resize alone\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/cotton data/train\", transform=transform[\"train\"])\n",
        "val_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/cotton data/test\", transform=transform[\"val\"])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AjbiFDcNkYi"
      },
      "outputs": [],
      "source": [
        "# PyTorch ka example\n",
        "torch.save(model.state_dict(), 'cotton_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71UcOT8gNmhM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save to your Google Drive\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/cotton_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CHSpE_3D6zQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Epoch range\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# ðŸ”¶ Plot: Training Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, marker='o', color='orange', label='Train Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ðŸ”· Plot: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, marker='o', color='green', label='Train Accuracy')\n",
        "plt.plot(epochs, test_accuracies, marker='s', color='blue', label='Test Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Train vs Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcb1JfqIIasa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_confusion_matrix(model, loader, class_names):\n",
        "    \"\"\"\n",
        "    Compute and display the confusion matrix for the model's predictions.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Trained model.\n",
        "        loader (DataLoader): DataLoader for the test dataset.\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Confusion matrix.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed for evaluation\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move to GPU/CPU\n",
        "            outputs = model(images)  # Forward pass\n",
        "            _, predicted = torch.max(outputs, 1)  # Get predicted classes\n",
        "            all_preds.extend(predicted.cpu().numpy())  # Store predictions\n",
        "            all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=range(len(class_names)))\n",
        "\n",
        "    # Display confusion matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    return cm\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the test dataset and DataLoader\n",
        "    test_dataset = datasets.ImageFolder(\n",
        "        \"/content/drive/MyDrive/cotton data/test\",\n",
        "        transform=transform[\"val\"]\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load(\"cotton_model.pth\"))\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Get class names from the dataset\n",
        "    class_names = test_dataset.classes  # List of class names\n",
        "\n",
        "    # Compute and display the confusion matrix\n",
        "    confusion_matrix_result = compute_confusion_matrix(model, test_loader, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx2tdH7Jacnj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data: Learning rate values per batch\n",
        "# Replace these with actual learning rates if you are using a learning rate scheduler\n",
        "batch_numbers = list(range(1, 51))  # Example: 100 batches\n",
        "learning_rates = [0.001 * (0.95 ** (batch // 10)) for batch in batch_numbers]  # Example LR decay\n",
        "\n",
        "# Plot Learning Rate vs. Batch Number\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(batch_numbers, learning_rates, color='blue', marker='o', markersize=3, label='Learning Rate')\n",
        "\n",
        "plt.title('Learning Rate vs. Batch Number')\n",
        "plt.xlabel('Batch Number')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbHAWZrzayul"
      },
      "outputs": [],
      "source": [
        "test_dir = \"/content/drive/MyDrive/cotton data/test\"\n",
        "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmxikRvXa4mR"
      },
      "outputs": [],
      "source": [
        "test_images = sorted(os.listdir(test_dir)) # since images in test folder are in alphabetical order\n",
        "test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jy1plTebNJO"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo_1gW5Wa7Yi"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    \"\"\"Converts image to array and return the predicted class\n",
        "        with highest probability\"\"\"\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "\n",
        "    return train_dataset.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u76K_otVcwgs"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask-ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFuk4vseI0Cy"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO58duCYghgE"
      },
      "outputs": [],
      "source": [
        "# Install required libraries (run this in Colab cell)\n",
        "# !pip install flask flask-ngrok torch torchvision pyngrok\n",
        "\n",
        "from flask import Flask, request, render_template_string, jsonify\n",
        "from pyngrok import ngrok, conf\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the EfficientNetV2 model class (same as in your training script)\n",
        "class EfficientNetV2Model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(EfficientNetV2Model, self).__init__()\n",
        "        self.base_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
        "        self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Set the number of classes (update this based on your dataset)\n",
        "num_classes = 7\n",
        "model = EfficientNetV2Model(num_classes)\n",
        "\n",
        "# Load your trained model file\n",
        "state_dict = torch.load('/content/cotton_model.pth', map_location=torch.device('cpu'))\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define image preprocessing transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to model's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pretrained models\n",
        "])\n",
        "\n",
        "# Define class labels (update based on your dataset)\n",
        "class_labels = ['Aphids','Army worm','Bacterial blight','Healthy','Powdery mildew','Target spot','Unknown']\n",
        "\n",
        "# Configure ngrok\n",
        "conf.get_default().auth_token = \"2sAaR9tq50mYwCQMZAuZp214SwT_5BFQ8WoeaG8okfuiVmoL2\"  # Replace with your ngrok token\n",
        "ngrok_tunnel = ngrok.connect(5000)\n",
        "print(' * Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string()\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'prediction': 'Undefined'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "    try:\n",
        "        image = Image.open(file.stream).convert('RGB')\n",
        "        image = transform(image).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            confidence, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "            confidence_score = confidence.item()\n",
        "            predicted_label = class_labels[predicted.item()]\n",
        "\n",
        "            print(f\"[DEBUG] Predict: {predicted_label} | Confidence: {confidence_score:.2f}\")\n",
        "\n",
        "            return jsonify({'prediction': predicted_label})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'prediction': 'Undefined', 'error': str(e)}), 500\n",
        "\n",
        "\n",
        "# Run the app\n",
        "app.run(port=5000)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}